"""removing the new recurrence tables

Revision ID: 1770a256287a
Revises: 833595f73ea1
Create Date: 2025-09-18 13:44:10.996777

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = '1770a256287a'
down_revision = '833595f73ea1'
branch_labels = None
depends_on = None


def upgrade():
    # --- 1) Drop FACTS first (they reference dims) ---

    # fact_service_event
    with op.batch_alter_table('fact_service_event', schema=None) as batch_op:
        # indexes can be dropped or just rely on table drop; keeping explicit = tidy
        batch_op.drop_index('ix_fact_service_event_job_id')
        batch_op.drop_index('ix_fse_date')
        batch_op.drop_index('ix_fse_loc_serv_date')
        batch_op.drop_index('ix_fse_source')
    op.drop_table('fact_service_event')

    # fact_monthly_service_need
    with op.batch_alter_table('fact_monthly_service_need', schema=None) as batch_op:
        batch_op.drop_index('ix_fmsn_loc')
        batch_op.drop_index('ix_fmsn_month')
        batch_op.drop_index('ix_fmsn_service')
    op.drop_table('fact_monthly_service_need')

    # --- 2) Drop DIMENSIONS next ---

    # dim_service
    with op.batch_alter_table('dim_service', schema=None) as batch_op:
        batch_op.drop_index('ix_dim_service_is_recurring')
        batch_op.drop_index('ix_dim_service_type')
    op.drop_table('dim_service')

    # dim_date
    with op.batch_alter_table('dim_date', schema=None) as batch_op:
        batch_op.drop_index('ix_dim_date_month_start')
    op.drop_table('dim_date')

    # dim_source (no extra indexes in your snippet)
    op.drop_table('dim_source')

    # --- 3) OPTIONAL: drop Postgres ENUM types after all dependents are gone ---
    op.execute("DROP TYPE IF EXISTS service_type_enum")
    op.execute("DROP TYPE IF EXISTS source_kind_enum")




def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('job_item_technician', schema=None) as batch_op:
        batch_op.drop_constraint('uq_job_item_id', type_='unique')

    op.create_table('fact_service_event',
    sa.Column('id', sa.BIGINT(), autoincrement=True, nullable=False),
    sa.Column('location_pk', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('service_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('date_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('source_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('job_id', sa.BIGINT(), autoincrement=False, nullable=True),
    sa.Column('completed_on', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('scheduled_for', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True),
    sa.Column('hours_actual', sa.NUMERIC(precision=10, scale=2), autoincrement=False, nullable=True),
    sa.Column('hours_booked', sa.NUMERIC(precision=10, scale=2), autoincrement=False, nullable=True),
    sa.Column('hours_estimated', sa.NUMERIC(precision=10, scale=2), autoincrement=False, nullable=True),
    sa.Column('tech_count', sa.SMALLINT(), autoincrement=False, nullable=True),
    sa.Column('multi_day', sa.BOOLEAN(), autoincrement=False, nullable=True),
    sa.Column('multi_tech_required', sa.BOOLEAN(), autoincrement=False, nullable=True),
    sa.Column('ingested_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=False),
    sa.CheckConstraint('hours_actual IS NULL OR hours_actual >= 0::numeric) AND (hours_booked IS NULL OR hours_booked >= 0::numeric) AND (hours_estimated IS NULL OR hours_estimated >= 0::numeric', name='ck_fse_nonnegative_hours'),
    sa.ForeignKeyConstraint(['date_id'], ['dim_date.id'], name='fact_service_event_date_id_fkey'),
    sa.ForeignKeyConstraint(['location_pk'], ['location.id'], name='fact_service_event_location_pk_fkey'),
    sa.ForeignKeyConstraint(['service_id'], ['dim_service.id'], name='fact_service_event_service_id_fkey'),
    sa.ForeignKeyConstraint(['source_id'], ['dim_source.id'], name='fact_service_event_source_id_fkey'),
    sa.PrimaryKeyConstraint('id', name='fact_service_event_pkey')
    )
    with op.batch_alter_table('fact_service_event', schema=None) as batch_op:
        batch_op.create_index('ix_fse_source', ['source_id'], unique=False)
        batch_op.create_index('ix_fse_loc_serv_date', ['location_pk', 'service_id', 'date_id'], unique=False)
        batch_op.create_index('ix_fse_date', ['date_id'], unique=False)
        batch_op.create_index('ix_fact_service_event_job_id', ['job_id'], unique=False)

    op.create_table('dim_date',
    sa.Column('id', sa.INTEGER(), server_default=sa.text("nextval('dim_date_id_seq'::regclass)"), autoincrement=True, nullable=False),
    sa.Column('d', sa.DATE(), autoincrement=False, nullable=False),
    sa.Column('day', sa.SMALLINT(), autoincrement=False, nullable=False),
    sa.Column('month', sa.SMALLINT(), autoincrement=False, nullable=False),
    sa.Column('year', sa.SMALLINT(), autoincrement=False, nullable=False),
    sa.Column('quarter', sa.SMALLINT(), autoincrement=False, nullable=False),
    sa.Column('month_start', sa.DATE(), autoincrement=False, nullable=False),
    sa.Column('month_name', sa.VARCHAR(length=12), autoincrement=False, nullable=False),
    sa.Column('week_of_year', sa.SMALLINT(), autoincrement=False, nullable=True),
    sa.Column('is_month_start', sa.BOOLEAN(), autoincrement=False, nullable=False),
    sa.Column('is_month_end', sa.BOOLEAN(), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('id', name='dim_date_pkey'),
    sa.UniqueConstraint('d', name='dim_date_d_key'),
    postgresql_ignore_search_path=False
    )
    with op.batch_alter_table('dim_date', schema=None) as batch_op:
        batch_op.create_index('ix_dim_date_month_start', ['month_start'], unique=False)

    op.create_table('fact_monthly_service_need',
    sa.Column('id', sa.BIGINT(), autoincrement=True, nullable=False),
    sa.Column('month_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('location_pk', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('service_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('hours_needed', sa.NUMERIC(precision=10, scale=2), autoincrement=False, nullable=False),
    sa.Column('is_booked', sa.BOOLEAN(), autoincrement=False, nullable=False),
    sa.Column('evidence_level', sa.SMALLINT(), autoincrement=False, nullable=True),
    sa.Column('events_count', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('last_computed_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=False),
    sa.ForeignKeyConstraint(['location_pk'], ['location.id'], name='fact_monthly_service_need_location_pk_fkey'),
    sa.ForeignKeyConstraint(['month_id'], ['dim_date.id'], name='fact_monthly_service_need_month_id_fkey'),
    sa.ForeignKeyConstraint(['service_id'], ['dim_service.id'], name='fact_monthly_service_need_service_id_fkey'),
    sa.PrimaryKeyConstraint('id', name='fact_monthly_service_need_pkey'),
    sa.UniqueConstraint('month_id', 'location_pk', 'service_id', name='uq_fmsn_month_loc_service')
    )
    with op.batch_alter_table('fact_monthly_service_need', schema=None) as batch_op:
        batch_op.create_index('ix_fmsn_service', ['service_id'], unique=False)
        batch_op.create_index('ix_fmsn_month', ['month_id'], unique=False)
        batch_op.create_index('ix_fmsn_loc', ['location_pk'], unique=False)

    op.create_table('dim_service',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('service_type', postgresql.ENUM('ANNUAL', 'PM', 'PLANNED_MAINT', 'NON_RECURRING', name='service_type_enum'), autoincrement=False, nullable=False),
    sa.Column('service_line', sa.VARCHAR(length=100), autoincrement=False, nullable=True),
    sa.Column('is_recurring', sa.BOOLEAN(), autoincrement=False, nullable=False),
    sa.Column('description', sa.VARCHAR(length=255), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name='dim_service_pkey'),
    sa.UniqueConstraint('service_type', 'service_line', name='uq_dim_service_type_line')
    )
    with op.batch_alter_table('dim_service', schema=None) as batch_op:
        batch_op.create_index('ix_dim_service_type', ['service_type'], unique=False)
        batch_op.create_index('ix_dim_service_is_recurring', ['is_recurring'], unique=False)

    op.create_table('dim_source',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('source_kind', postgresql.ENUM('HISTORICAL_JOB', 'SCHEDULED_JOB', 'LOCATION_TAG', name='source_kind_enum'), autoincrement=False, nullable=False),
    sa.Column('priority', sa.SMALLINT(), autoincrement=False, nullable=False),
    sa.PrimaryKeyConstraint('id', name='dim_source_pkey'),
    sa.UniqueConstraint('source_kind', name='dim_source_source_kind_key')
    )
    # ### end Alembic commands ###
