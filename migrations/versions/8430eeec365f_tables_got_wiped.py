"""tables got wiped

Revision ID: 8430eeec365f
Revises: 5afea14cb20b
Create Date: 2025-04-24 12:30:24.094523

"""
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = '8430eeec365f'
down_revision = '5afea14cb20b'
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('deficiency_record',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('deficiency_id', sa.String(length=100), nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), nullable=True),
    sa.Column('status', sa.String(length=50), nullable=True),
    sa.Column('reported_on', sa.DateTime(timezone=True), nullable=True),
    sa.Column('address', sa.String(length=255), nullable=True),
    sa.Column('location_name', sa.String(length=255), nullable=True),
    sa.Column('is_monthly_access', sa.Boolean(), nullable=True),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('proposed_solution', sa.Text(), nullable=True),
    sa.Column('company', sa.String(length=255), nullable=True),
    sa.Column('tech_name', sa.String(length=255), nullable=True),
    sa.Column('tech_image_link', sa.String(length=1024), nullable=True),
    sa.Column('job_link', sa.String(length=1024), nullable=True),
    sa.Column('service_line_name', sa.String(length=255), nullable=True),
    sa.Column('service_line_icon_link', sa.String(length=1024), nullable=True),
    sa.Column('severity', sa.String(length=50), nullable=True),
    sa.Column('is_archived', sa.Boolean(), nullable=True),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('deficiency_id')
    )
    with op.batch_alter_table('deficiency_record', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('ix_deficiency_record_is_archived'), ['is_archived'], unique=False)

    op.create_table('job_summary',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('week_start', sa.Date(), nullable=False),
    sa.Column('total_jobs_processed', sa.Integer(), nullable=True),
    sa.Column('total_tech_hours_processed', sa.Float(), nullable=True),
    sa.Column('jobs_by_type', sa.JSON(), nullable=True),
    sa.Column('hours_by_type', sa.JSON(), nullable=True),
    sa.Column('updated_at', sa.DateTime(timezone=True), nullable=True),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('week_start')
    )
    op.create_table('processing_status',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('week_start', sa.Date(), nullable=False),
    sa.Column('jobs_to_be_marked_complete', sa.Integer(), nullable=True),
    sa.Column('oldest_job_date', sa.Date(), nullable=True),
    sa.Column('oldest_job_address', sa.String(length=255), nullable=True),
    sa.Column('oldest_job_type', sa.String(length=255), nullable=True),
    sa.Column('job_type_count', sa.JSON(), nullable=True),
    sa.Column('number_of_pink_folder_jobs', sa.Integer(), nullable=True),
    sa.Column('oldest_inspection_date', sa.Date(), nullable=True),
    sa.Column('oldest_inspection_address', sa.String(length=255), nullable=True),
    sa.Column('updated_at', sa.DateTime(timezone=True), nullable=True),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('week_start')
    )
    op.create_table('processor_metrics',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('week_start', sa.Date(), nullable=False),
    sa.Column('processor_name', sa.String(length=255), nullable=False),
    sa.Column('jobs_processed', sa.Integer(), nullable=True),
    sa.Column('hours_processed', sa.Float(), nullable=True),
    sa.Column('updated_at', sa.DateTime(timezone=True), nullable=True),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('week_start', 'processor_name', name='unique_week_processor')
    )
    op.create_table('scheduling_attack',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('month_start', sa.Date(), nullable=False),
    sa.Column('released_fa_jobs', sa.Integer(), nullable=True),
    sa.Column('released_fa_tech_hours', sa.Float(), nullable=True),
    sa.Column('scheduled_fa_jobs', sa.Integer(), nullable=True),
    sa.Column('scheduled_fa_tech_hours', sa.Float(), nullable=True),
    sa.Column('to_be_scheduled_fa_jobs', sa.Integer(), nullable=True),
    sa.Column('to_be_scheduled_fa_tech_hours', sa.Float(), nullable=True),
    sa.Column('released_sprinkler_jobs', sa.Integer(), nullable=True),
    sa.Column('released_sprinkler_tech_hours', sa.Float(), nullable=True),
    sa.Column('scheduled_sprinkler_jobs', sa.Integer(), nullable=True),
    sa.Column('scheduled_sprinkler_tech_hours', sa.Float(), nullable=True),
    sa.Column('to_be_scheduled_sprinkler_jobs', sa.Integer(), nullable=True),
    sa.Column('to_be_scheduled_sprinkler_tech_hours', sa.Float(), nullable=True),
    sa.Column('jobs_to_be_scheduled', sa.JSON(), nullable=True),
    sa.Column('not_counted_fa_locations', sa.JSON(), nullable=True),
    sa.Column('updated_at', sa.DateTime(timezone=True), nullable=True),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('month_start')
    )
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('scheduling_attack')
    op.drop_table('processor_metrics')
    op.drop_table('processing_status')
    op.drop_table('job_summary')
    with op.batch_alter_table('deficiency_record', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_deficiency_record_is_archived'))

    op.drop_table('deficiency_record')
    # ### end Alembic commands ###
